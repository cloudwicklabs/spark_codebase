cassandra {
  keyspace = "loganalytics"

  host = "localhost"

  # native_transport_port
  #   port for the CQL native transport to listen for clients on
  #
  nativePort = 9042
  # rpc_port
  #   port for Thrift to listen for clients on
  rpcPort = 9160

  replication.strategy = "SimpleStrategy"
  replication.factor = 3

  # Size of pool used for cassandra operations
  concurrency = 10
}

kafka {
  # list of zookeeper quorums to connect to
  zookeeper.quorum = "localhost:2181"

  # group id for this consumer
  consumer.group = "loganalytics"

  # comman seperated values of topics to fetch data from
  topics = "log-events"

  # number of threads for consuming the topics (ideally equal number of partitions)
  threads = 1
}

kinesis {
  # name of the kinesis stream to connect to, if this stream does not exist it will be created
  stream.name = "logevents"

  # `app.name` is used to create a DynamoDB table to maintain state for the
  # application and should change as `stream.name` changes. Possible errors if not changed:
  # com.amazonaws.services.kinesis.model.InvalidArgumentException: StartingSequenceNumber 49550063159425038533739345959303184138691727877071699970 used in GetShardIterator on shard shardId-000000000000 in stream logevents under account XXXXXXXXX is invalid because it did not come from this stream. (Service: AmazonKinesis; Status Code: 400; Error Code: InvalidArgumentException; Request ID: c2dd700d-eb8f-11e4-a62f-8fc087d45d29)
  app.name = "LogAnalyzer-"${kinesis.stream.name}

  # LATEST: most recent data.
  # TRIM_HORIZON: oldest available data.
  # Note: This only effects the first run of this application on a stream.
  initial.position = "TRIM_HORIZON"

  # aws access key
  aws {
    access.key = ""

    # aws secret key
    secret.key = ""

    # kinesis enpoint url to connect to
    endpoint.url = "kinesis.us-west-2.amazonaws.com"
  }
}